---
layout: post
title: "Some Thoughts"
date: 2025-12-04 
category: Technology
tags: [AI, Ethics, Future]
author: Ethereal Firmament
---


## AI Alignment
It is likely that in the next few years we will see an artificial intelligence that surpasses the vast majority of humans in cognitive ability. By that I mean 1) Has a larger and more detailed memory about all recorded history, events and human endeavours 2) Is able to assimilate new information faster and more comprehensively 3) Is able to learn new skills based on a set of rules and data, faster and to a greater competence.

Now - there is the question of this intelligence being fundamentally different to a human intelligence. Clearly it is structurally different; it is digital in its computation, and performs inference in silicon hardware rather than fleshy brains. However, it is not so clear to me whether it is fundamentally different. I have not seen a compelling argument that brains are capable of performing some process that is irreplicable by machines. Consider a computer than has been designed to replicate the exact structure of a human brain (of course this is inefficient). Or even consider a perfect replica of a brain, structurally similar on the cellular of even atomic level. How then can one claim that this is not intelligent if the brain it was to replicate is? 

It is also odd how we separate the brain from the body on matters of computation, but the idea of the brain itself being intelligent when the body is removed feels strange. 

- The idea that there may be millions of instances of one intelligence. What then is intelligent?
- Could an instance of an intelligence be conscious?
- The fact that there can be innumerable instances of one intelligence, all perfectly aligned, suggests a massive parallel computation and inference capability.
-- Even a modestly intelligence AI, that could leverage parallelisation of millions of instances of itself would surpass humans in almost any endeavour.
-- This naturally suggests compute should be proportional to productivity, up to a saturation point where a given problem cannot be broken down into sub-tasks/sub-inferences palatable by any given instance.
-- There is also the natural idea of a centralised intelligence: A 'boss' with complete context, directing 'managers' who themselves direct individual agents. The boss would be responsible for the 'grand design' of the solution, the managers for handling large subtasks, and the individual agents at the bottom of the tree for managing individual, indivisible tasks or inferences. However, this chain of command seems like one would need multiple different AI systems. Indeed, the chain of command only works if the subordinates only listen to their manager, and so on up to the boss. If all of the agents were instances of the same system, then by virtue of the tree structure, the agents at the bottom of the ladder would have a majority vote, and their 'will' could travel upstream. This is not an issue until it is considered that only the 'boss' has the complete context. Theres the interesting problem of the 'boss' having to prompt itself. Is this a benefit or an oversight? The 'boss' can leverage its own strength, but also every instance of the agent has the same oversights and weaknesses. It seems there should be a heirachy of not just context but also capability/intelligence.
-- I think this is a human way of thinking. I think there is more promise in a message-passing based completely parallel system.


Intelligence = horizon + abstraction + decomposition + memory + inference-compute

The Devil doesn't have horns. He has a utility function. And you are just standing on his resources.

## Modern dating

## Nobility

## Betrayal

## Meaning and purpose

## Friendship

## Neuroticism, intelligence, EO, and isolation: two edges of a very sharp sword

## Success and delusion

Author: Ethereal Firmament
